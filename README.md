# Fase 1 - Proyecto MLOps: PredicciÃ³n de Obesidad

## ğŸ“‹ InformaciÃ³n del Proyecto

**Equipo**: 52  
**Dataset**: Obesity Estimation Dataset  
**Objetivo**: Desarrollar un modelo de Machine Learning para predecir niveles de obesidad basado en caracterÃ­sticas biomÃ©tricas y hÃ¡bitos de vida  
**Fase**: 1 - AnÃ¡lisis Exploratorio y PreparaciÃ³n de Datos  

---

## ğŸ¯ 1. AnÃ¡lisis de Requerimientos

### ProblemÃ¡tica Identificada
El dataset de obesidad presenta un problema de **clasificaciÃ³n multiclase** donde necesitamos predecir el nivel de obesidad de una persona basado en caracterÃ­sticas biomÃ©tricas y hÃ¡bitos de vida. La obesidad es un problema de salud pÃºblica crÃ­tico que requiere herramientas de predicciÃ³n precisas para intervenciÃ³n temprana.

### Propuesta de Valor con ML
Una soluciÃ³n de Machine Learning puede:
- **Predecir niveles de obesidad** con alta precisiÃ³n basado en caracterÃ­sticas medibles
- **Identificar factores de riesgo** mÃ¡s influyentes en el desarrollo de obesidad
- **Facilitar intervenciones tempranas** para prevenir complicaciones de salud
- **Optimizar recursos mÃ©dicos** dirigiendo atenciÃ³n a pacientes de mayor riesgo
- **Personalizar tratamientos** basado en perfiles de riesgo individuales

### ML Canvas
```
PROBLEMA:
- ClasificaciÃ³n multiclase (7 niveles de obesidad)
- Dataset con 2111 registros y 17 caracterÃ­sticas
- Variables: biomÃ©tricas, demogrÃ¡ficas y hÃ¡bitos de vida

SOLUCIÃ“N:
- Modelo de clasificaciÃ³n para predecir niveles de obesidad
- Algoritmos: Random Forest, SVM, Logistic Regression
- MÃ©tricas: Accuracy, Precision, Recall, F1-Score

DATOS:
- Fuente: Dataset de obesidad con caracterÃ­sticas biomÃ©tricas
- Calidad: Limpio despuÃ©s de EDA y preprocesamiento
- Volumen: 2111 registros, adecuado para entrenamiento

IMPACTO:
- Mejora en detecciÃ³n temprana de obesidad
- OptimizaciÃ³n de recursos mÃ©dicos
- PrevenciÃ³n de complicaciones de salud
```

---

## ğŸ”§ 2. ManipulaciÃ³n y PreparaciÃ³n de Datos

### Dataset Utilizado
- **Original**: `obesity_estimation_original.csv` (2111, 17) - Referencia limpia
- **Modified**: `obesity_estimation_modified.csv` (2153, 18) - Con problemas para practicar
- **Creado**: Dataset limpio resultado del proceso de limpieza

### Problemas Identificados y Solucionados

#### ğŸ” Inconsistencias Detectadas:
1. **Texto inconsistente**: Espacios, mayÃºsculas/minÃºsculas mixtas
2. **Valores N/A**: 'N/A', 'unknown', 'bad' como strings
3. **Columna extra**: 'mixed_type_col' no presente en original
4. **Valores extremos**: Edad 706 aÃ±os, peso 1040 kg, altura 57 metros
5. **Filas extra**: 42 filas adicionales en dataset modificado

#### âœ… Estrategia de Limpieza Implementada:
1. **EliminaciÃ³n de columna extra**: `mixed_type_col`
2. **Limpieza de texto**: NormalizaciÃ³n de espacios y caracteres
3. **ConversiÃ³n de tipos**: NumÃ©ricos y categÃ³ricos correctos
4. **ValidaciÃ³n de rangos realistas**:
   - Edad: 14-100 aÃ±os
   - Altura: 1.0-2.5 metros
   - Peso: 20-200 kg
5. **NormalizaciÃ³n categÃ³rica**: Formato estÃ¡ndar (ej: 'obesity_type_iii')
6. **ImputaciÃ³n inteligente**: Mediana para numÃ©ricas, moda para categÃ³ricas
7. **Ajuste de dimensiones**: EliminaciÃ³n de filas extra

### Herramientas Utilizadas
- **Python**: Pandas, NumPy para manipulaciÃ³n de datos
- **VisualizaciÃ³n**: Matplotlib, Seaborn para EDA
- **Preprocesamiento**: Scikit-learn para transformaciones
- **Control de versiones**: Git para trazabilidad

---

## ğŸ“Š 3. ExploraciÃ³n y Preprocesamiento de Datos

### AnÃ¡lisis Exploratorio Realizado

#### ğŸ“ˆ EstadÃ­sticas Descriptivas:
- **Dataset final**: (2111, 17) registros y caracterÃ­sticas
- **Valores faltantes**: 0 (despuÃ©s de limpieza)
- **Variables numÃ©ricas**: 8 (Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE)
- **Variables categÃ³ricas**: 9 (Gender, family_history, FAVC, CAEC, SMOKE, SCC, CALC, MTRANS, NObeyesdad)

#### ğŸ¯ Variable Objetivo (NObeyesdad):
```
DistribuciÃ³n de clases:
- obesity_type_i: 352 personas (16.7%)
- obesity_type_iii: 310 personas (14.7%)
- obesity_type_ii: 293 personas (13.9%)
- overweight_level_i: 289 personas (13.7%)
- overweight_level_ii: 286 personas (13.5%)
- normal_weight: 283 personas (13.4%)
- insufficient_weight: 271 personas (12.8%)
```

#### ğŸ“Š AnÃ¡lisis de Correlaciones:
- **No hay correlaciones fuertes** (|r| > 0.3) entre variables numÃ©ricas
- **Variables independientes** entre sÃ­
- **BMI con correlaciones moderadas** con peso y altura (esperado)
- **Favorable para ML**: Sin multicolinealidad severa

### TÃ©cnicas de Preprocesamiento Aplicadas

#### ğŸ”„ Transformaciones Realizadas:
1. **CodificaciÃ³n categÃ³rica**:
   - Variables binarias: Label encoding (0/1)
   - Variables multiclase: One-hot encoding
2. **NormalizaciÃ³n numÃ©rica**: StandardScaler aplicado
3. **EliminaciÃ³n de duplicados**: Datos Ãºnicos
4. **Manejo de outliers**: Valores extremos corregidos con rangos realistas

#### ğŸ“‹ MÃ©tricas de Calidad:
- **Completitud**: 100% (sin valores faltantes)
- **Consistencia**: Formato uniforme en todas las variables
- **Validez**: Rangos realistas para variables biomÃ©tricas
- **Unicidad**: Sin duplicados despuÃ©s de limpieza

---

## ğŸ”„ 4. Versionado de Datos

### Estrategia de Versionado Implementada

#### ğŸ“ Estructura de Datos:
```
db/
â”œâ”€â”€ obesity_estimation_original.csv    # Dataset original (referencia)
â”œâ”€â”€ obesity_estimation_modified.csv   # Dataset con problemas
â””â”€â”€ obesity_estimation_clean.csv      # Dataset limpio (resultado)
```

#### ğŸ·ï¸ Versiones Documentadas:
1. **v1.0**: Dataset original (limpio del profesor)
2. **v1.1**: Dataset modificado (con problemas para practicar)
3. **v2.0**: Dataset creado (limpio despuÃ©s de EDA)

#### ğŸ“ Registro de Cambios:
- **EliminaciÃ³n**: Columna 'mixed_type_col'
- **CorrecciÃ³n**: 165 valores extremos fuera de rangos realistas
- **ImputaciÃ³n**: Valores faltantes con mediana/moda
- **NormalizaciÃ³n**: Variables categÃ³ricas a formato estÃ¡ndar
- **Ajuste**: EliminaciÃ³n de 42 filas extra

### Herramientas de Versionado
- **Git**: Control de versiones del cÃ³digo y documentaciÃ³n
- **DVC**: Versionado de datasets (prÃ³xima implementaciÃ³n)
- **DocumentaciÃ³n**: Registro detallado de modificaciones

---

## ğŸ¤– 5. ConstrucciÃ³n, Ajuste y EvaluaciÃ³n de Modelos

### Algoritmos Seleccionados

#### ğŸ¯ JustificaciÃ³n de SelecciÃ³n:
Basado en el anÃ¡lisis de correlaciones y caracterÃ­sticas del dataset:

1. **Random Forest**:
   - âœ… Maneja bien variables independientes
   - âœ… Robusto a outliers
   - âœ… Proporciona importancia de caracterÃ­sticas
   - âœ… Bueno para clasificaciÃ³n multiclase

2. **Support Vector Machine (SVM)**:
   - âœ… Efectivo con datos normalizados
   - âœ… Maneja bien espacios de alta dimensiÃ³n
   - âœ… Bueno para clasificaciÃ³n multiclase

3. **Logistic Regression**:
   - âœ… Interpretable y rÃ¡pido
   - âœ… Sin problemas de multicolinealidad
   - âœ… Bueno para clasificaciÃ³n multiclase

### MÃ©tricas de EvaluaciÃ³n Planificadas

#### ğŸ“Š MÃ©tricas Principales:
- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision**: Por clase (macro y micro)
- **Recall**: Por clase (macro y micro)
- **F1-Score**: Balance entre precision y recall
- **Confusion Matrix**: VisualizaciÃ³n de errores por clase

#### ğŸ¯ MÃ©tricas EspecÃ­ficas:
- **Balanced Accuracy**: Considerando desbalance de clases
- **ROC-AUC**: Para evaluaciÃ³n multiclase
- **Cross-validation**: ValidaciÃ³n robusta con k-fold

### Estrategia de Entrenamiento

#### ğŸ”„ DivisiÃ³n de Datos:
- **Train**: 70% (1477 registros)
- **Validation**: 15% (317 registros)
- **Test**: 15% (317 registros)

#### âš™ï¸ Ajuste de HiperparÃ¡metros:
- **Grid Search**: BÃºsqueda exhaustiva de parÃ¡metros
- **Random Search**: BÃºsqueda aleatoria para eficiencia
- **Cross-validation**: ValidaciÃ³n durante ajuste

---

## ğŸ‘¥ Roles y Responsabilidades del Equipo

### ğŸ§‘â€ğŸ’» Data Engineer
- **Responsabilidades**:
  - Limpieza y preparaciÃ³n de datos
  - ImplementaciÃ³n de pipelines de datos
  - Versionado con DVC
  - OptimizaciÃ³n de almacenamiento
- **Actividades Realizadas**:
  - EDA completo del dataset
  - Limpieza de inconsistencias
  - NormalizaciÃ³n de variables
  - DocumentaciÃ³n de cambios

### ğŸ§‘â€ğŸ”¬ Data Scientist
- **Responsabilidades**:
  - AnÃ¡lisis exploratorio de datos
  - IdentificaciÃ³n de patrones y tendencias
  - SelecciÃ³n de caracterÃ­sticas
  - Preprocesamiento avanzado
- **Actividades Realizadas**:
  - AnÃ¡lisis de correlaciones
  - Visualizaciones profesionales
  - DetecciÃ³n de outliers
  - AnÃ¡lisis de distribuciÃ³n de clases

### ğŸ§‘â€ğŸ’» ML Engineer
- **Responsabilidades**:
  - ConstrucciÃ³n de modelos
  - OptimizaciÃ³n de hiperparÃ¡metros
  - EvaluaciÃ³n de rendimiento
  - ImplementaciÃ³n de pipelines ML
- **Actividades Planificadas**:
  - ImplementaciÃ³n de algoritmos
  - ValidaciÃ³n cruzada
  - ComparaciÃ³n de modelos
  - OptimizaciÃ³n de rendimiento

### ğŸ§‘â€ğŸ’¼ Product Manager
- **Responsabilidades**:
  - DefiniciÃ³n de requerimientos
  - AnÃ¡lisis de valor de negocio
  - CoordinaciÃ³n de equipo
  - DocumentaciÃ³n ejecutiva
- **Actividades Realizadas**:
  - AnÃ¡lisis de problemÃ¡tica
  - Propuesta de valor
  - CoordinaciÃ³n de entregables
  - DocumentaciÃ³n de resultados

---

## ğŸ“ˆ Resultados Obtenidos

### âœ… Logros de la Fase 1:

#### ğŸ¯ Calidad de Datos:
- **Dataset limpio**: (2111, 17) sin valores faltantes
- **Formato consistente**: Variables normalizadas
- **Rangos vÃ¡lidos**: Valores realistas para variables biomÃ©tricas
- **Sin duplicados**: Datos Ãºnicos y confiables

#### ğŸ“Š Insights Clave:
- **DistribuciÃ³n balanceada**: Clases relativamente equilibradas
- **Variables independientes**: Sin multicolinealidad severa
- **BMI relevante**: Correlaciones esperadas con peso/altura
- **HÃ¡bitos influyentes**: Variables de estilo de vida importantes

#### ğŸ”§ PreparaciÃ³n para ML:
- **Datos preprocesados**: Listos para entrenamiento
- **CaracterÃ­sticas seleccionadas**: Todas las variables relevantes
- **Formato estÃ¡ndar**: Compatible con algoritmos ML
- **DocumentaciÃ³n completa**: Proceso reproducible

---

## ğŸ¯ Conclusiones y Reflexiones

### âœ… Fortalezas del AnÃ¡lisis:
1. **Limpieza exhaustiva**: IdentificaciÃ³n y correcciÃ³n de todos los problemas
2. **AnÃ¡lisis profundo**: EDA completo con visualizaciones profesionales
3. **DocumentaciÃ³n detallada**: Proceso completamente documentado
4. **PreparaciÃ³n sÃ³lida**: Dataset listo para modelado ML

### ğŸ”„ Ãreas de Mejora:
1. **Versionado avanzado**: Implementar DVC para mejor trazabilidad
2. **AnÃ¡lisis de caracterÃ­sticas**: Feature engineering mÃ¡s avanzado
3. **ValidaciÃ³n externa**: ComparaciÃ³n con datasets similares
4. **AutomatizaciÃ³n**: Pipelines mÃ¡s automatizados

### ğŸš€ Estrategias Implementadas:
1. **Enfoque sistemÃ¡tico**: Proceso estructurado de limpieza
2. **ValidaciÃ³n continua**: ComparaciÃ³n con dataset original
3. **DocumentaciÃ³n en tiempo real**: Registro de cada cambio
4. **PreparaciÃ³n para escalabilidad**: Estructura preparada para ML

### ğŸ“‹ PrÃ³ximos Pasos:
- âœ… Dataset limpio y listo para modelado
- âœ… AnÃ¡lisis exploratorio completado
- âœ… Preprocesamiento aplicado
- âœ… VerificaciÃ³n de calidad realizada
- ğŸ”„ ImplementaciÃ³n de modelos ML
- ğŸ”„ EvaluaciÃ³n y comparaciÃ³n de algoritmos
- ğŸ”„ OptimizaciÃ³n de hiperparÃ¡metros

---

## ğŸ“ Estructura del Proyecto

```
Equipo52_MLOPS/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ FASE 1 Avance del proyecto/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ obesity_estimation_original.csv
â”‚   â”‚   â””â”€â”€ obesity_estimation_modified.csv
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ EDA.ipynb
â””â”€â”€ docs/
    â””â”€â”€ (documentaciÃ³n adicional)
```

---

## ğŸ› ï¸ InstalaciÃ³n y Uso

### Requisitos
```bash
pip install -r requirements.txt
```

### EjecuciÃ³n del EDA
```bash
jupyter notebook FASE\ 1\ Avance\ del\ proyecto/notebooks/EDA.ipynb
```

---

## ğŸ“ Contacto del Equipo

**Equipo 52 - MLOps**  
**Instituto TecnolÃ³gico de Monterrey**

---

*Este documento representa el avance de la Fase 1 del proyecto MLOps para predicciÃ³n de obesidad, demostrando competencias en anÃ¡lisis exploratorio, limpieza de datos y preparaciÃ³n para modelado de Machine Learning.*